{"cells":[{"cell_type":"code","execution_count":717,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"18\n979\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 979 entries, 0 to 978\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      979 non-null    object\n 1   title   979 non-null    object\n 2   body    979 non-null    object\n 3   date    979 non-null    object\ndtypes: object(4)\nmemory usage: 15.4+ KB\nMost common words on 2020-03-31\n*****\n[('movie', 36), ('movies', 18), ('film', 12), ('time', 8), ('good', 6)]\n\nMost common words on 2020-04-01\n*****\n[('movie', 32), ('movies', 19), ('films', 6), ('anyone', 5), ('love', 5)]\n\nMost common words on 2020-04-03\n*****\n[('movie', 41), ('movies', 28), ('film', 11), ('films', 9), ('love', 7)]\n\nMost common words on 2020-04-02\n*****\n[('movie', 30), ('movies', 24), ('films', 10), ('film', 8), ('time', 7)]\n\nMost common words on 2020-03-30\n*****\n[('film', 7), ('movies', 4), ('watch', 3), ('character', 3), ('4', 2)]\n\nMost common words on 2020-04-06\n*****\n[('movie', 15), ('movies', 12), ('films', 9), ('watch', 7), ('film', 7)]\n\nMost common words on 2020-04-04\n*****\n[('movie', 29), ('movies', 13), ('time', 8), ('films', 8), ('like', 7)]\n\nMost common words on 2020-04-05\n*****\n[('movie', 32), ('movies', 29), ('help', 12), ('film', 11), ('time', 10)]\n\n"}],"source":"import nltk\n\n# nltk.download()\nfrom collections import Counter\n\nimport pprint\nimport numpy\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nimport random\n\nimport pandas as pd\nimport praw\nimport datetime as dt\nfrom IPython import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setup your credentials @ apps.reddit.com\nreddit = praw.Reddit(\n    client_id=PERSONAL_USE_SCRIPT_14_CHARS,\n    client_secret=SECRET_KEY_27_CHARS,\n    user_agent=YOUR_APP_NAME,\n    username=YOUR_REDDIT_USER_NAME,\n    password=YOUR_REDDIT_LOGON_PASSWORD,\n)\n\n\nsubreddit = \"movies\"\nkeyword = \"coronavirus\"\n\n\n# Pulling posts based on keyword search. This allows us to filter posts based\n# the keyword we are interested in. We can replace this for loop in the code below.\n\n\nposts = set()\nfor submission in reddit.subreddit(subreddit).search(\n    keyword, sort=\"top\", time_filter=\"week\", limit=None\n):\n    posts.add(submission.title)\n\nprint(len(posts))\n\n\n# Pulling top posts regardless of keyword. Same can be done for hot posts.\n# \"Best\" is the highest upvote to downvote ratio, \"top\" is the most upvotes regardless of downvotes, and \"hot\" is the most upvotes recently.\n\n\nposts = {\"id\": [], \"title\": [], \"body\": [], \"created\": []}\n\nfor submission in reddit.subreddit(subreddit).top(time_filter=\"week\", limit=None):\n    if not submission.stickied:\n\n        posts[\"id\"].append(submission.id)\n        posts[\"title\"].append(submission.title)\n        posts[\"body\"].append(submission.selftext)\n        posts[\"created\"].append(submission.created)\n    # display.clear_output()\nprint(len(posts[\"title\"]))\n\ndf_posts = pd.DataFrame(posts)\n\n\ndef get_date(created):\n    return dt.datetime.fromtimestamp(created).strftime(\"%Y-%m-%d\")\n\n\ntimestamp = df_posts[\"created\"].apply(get_date)\ndf_posts = df_posts.assign(date=timestamp)\ndel df_posts[\"created\"]\ndf_posts\n# Replace missing values in post body with empty strings\ndf_posts[\"body\"].fillna(value=\"\", inplace=True)\ndf_posts.info()\n\n# Adding features to our dataframe.\n# Length of title\ndf_posts[\"title_length\"] = df_posts[\"title\"].apply(lambda x: len(x))\n\n# df_posts.set_index(\"date\", inplace=True)\ndf_posts.reset_index(inplace=True)\ndf_posts.head()\n\n\ndfList = list(set(df_posts[\"date\"]))\ndfNames = [\"df\" + row for row in dfList]\n\nfor i, row in enumerate(dfList):\n    dfName = dfNames[i]\n    dfNew = df_posts[df_posts[\"date\"] == row]\n    dfNames[i] = dfNew\n\n\ntokenizer = nltk.RegexpTokenizer(r\"[\\w']+\")\ncommon_words = []\n\nfor df, name in zip(dfNames, dfList):\n    all_titles = \" \".join([x.lower() for x in df[\"title\"]])\n    words = list(tokenizer.tokenize(all_titles))\n    words = [x for x in words if x not in stopwords.words(\"english\")]\n\n    common_words.append(words)\n    print(\"Most common words on \" + name, \"*****\", sep=\"\\n\")\n    pprint.pprint(Counter(words).most_common(5))\n    print()"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}